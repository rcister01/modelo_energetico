{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95ebb26",
   "metadata": {},
   "source": [
    "## Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac92f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215e969",
   "metadata": {},
   "source": [
    "## Cargamos los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0be5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 12115)\n",
      "(7500, 5376)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('../raw_data/X.csv', index_col = 0)\n",
    "y = pd.read_csv('../raw_data/y.csv', index_col = 0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31105a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q_AC_OFFICE_0', 'Q_AC_OFFICE_1', 'Q_AC_OFFICE_2', 'Q_AC_OFFICE_3',\n",
       "       'Q_AC_OFFICE_4', 'Q_AC_OFFICE_5', 'Q_AC_OFFICE_6', 'Q_AC_OFFICE_7',\n",
       "       'Q_AC_OFFICE_8', 'Q_AC_OFFICE_9',\n",
       "       ...\n",
       "       'T_INT_OFFICE_662', 'T_INT_OFFICE_663', 'T_INT_OFFICE_664',\n",
       "       'T_INT_OFFICE_665', 'T_INT_OFFICE_666', 'T_INT_OFFICE_667',\n",
       "       'T_INT_OFFICE_668', 'T_INT_OFFICE_669', 'T_INT_OFFICE_670',\n",
       "       'T_INT_OFFICE_671'],\n",
       "      dtype='object', length=5376)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b21db68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q_AC_OFFICE',\n",
       " 'Q_HEAT_OFFICE',\n",
       " 'Q_PEOPLE',\n",
       " 'Q_EQP',\n",
       " 'Q_LIGHT',\n",
       " 'Q_AHU_C',\n",
       " 'Q_AHU_H',\n",
       " 'T_INT_OFFICE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_y = [x[:-4] for x in y.columns if '671' in x]\n",
    "columns_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8eea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloco las variables de temperatura (T_INT_OFFICE) como features\n",
    "cols_t = y.iloc[: , -672:]\n",
    "X = pd.concat([X, cols_t], axis = 1)\n",
    "y = y.iloc[: , :-672]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026d4d3",
   "metadata": {},
   "source": [
    "## Analizamos las variables que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5fc718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airchange_infiltration_vol_per_h', 'capacitance_kJ_perdegreK_perm3',\n",
       "       'power_VCV_kW_heat', 'power_VCV_kW_clim', 'nb_occupants', 'nb_PCs',\n",
       "       'facade_1_thickness_2', 'facade_1_window_area_percent',\n",
       "       'facade_2_thickness_2', 'facade_2_window_area_percent',\n",
       "       'facade_3_thickness_2', 'facade_3_window_area_percent',\n",
       "       'facade_4_thickness_2', 'facade_4_window_area_percent',\n",
       "       'roof_thickness_2', 'ground_thickness_2', 'init_day', 'init_month',\n",
       "       'init_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_c = X.columns[0:19]\n",
    "columns_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb12d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_c = X.columns[0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac2ee4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ac_t_conf',\n",
       " 'ac_t_red',\n",
       " 'ac_mask',\n",
       " 'heat_t_conf',\n",
       " 'heat_t_red',\n",
       " 'heat_mask',\n",
       " 'ventilation_t',\n",
       " 'ventilation_vol',\n",
       " 'ventilation_mask',\n",
       " 'occupancy',\n",
       " 'pc_on_mask',\n",
       " 'DNI',\n",
       " 'IBEAM_H',\n",
       " 'IBEAM_N',\n",
       " 'IDIFF_H',\n",
       " 'IGLOB_H',\n",
       " 'RHUM',\n",
       " 'TAMB',\n",
       " 'T_INT_OFFICE']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_s = [x[:-4] for x in X.columns if '671' in x]\n",
    "columns_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef29824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q_AC_OFFICE',\n",
       " 'Q_HEAT_OFFICE',\n",
       " 'Q_PEOPLE',\n",
       " 'Q_EQP',\n",
       " 'Q_LIGHT',\n",
       " 'Q_AHU_C',\n",
       " 'Q_AHU_H']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_y = [x[:-4] for x in y.columns if '671' in x]\n",
    "columns_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c1eec",
   "metadata": {},
   "source": [
    "## Escenario - Dataset con una fila para cada hora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3912408",
   "metadata": {},
   "source": [
    "### Cargamos los datasets (si ya están en el repositorio ir a última celda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = X\n",
    "\n",
    "X_per_h = None\n",
    "for i in range(X_tmp.shape[0]):\n",
    "    new_data_dict = {}\n",
    "    for col in columns_s:\n",
    "        columns_s_j = [f'{col}_{j}' for j in range(672)]\n",
    "        new_data_dict[col] = X_tmp[columns_s_j].iloc[[i]].values[0].T\n",
    "    new_df = pd.DataFrame(data = new_data_dict)\n",
    "    for col in columns_c:\n",
    "        new_df[col] = X_tmp.loc[i, col]\n",
    "    if not(X_per_h is None):\n",
    "        X_per_h = pd.concat([X_per_h, new_df])\n",
    "        print(f'Se agregaron {i*672} filas de {X_tmp.shape[0]*672}')\n",
    "    else:\n",
    "        X_per_h = new_df\n",
    "\n",
    "X_per_h.to_csv('../raw_data/X_per_h.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d81a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp = y\n",
    "\n",
    "y_per_h = None\n",
    "for i in range(y_tmp.shape[0]):\n",
    "    new_data_dict = {}\n",
    "    for col in columns_y:\n",
    "        columns_y_j = [f'{col}_{j}' for j in range(672)]\n",
    "        new_data_dict[col] = y_tmp[columns_y_j].iloc[[i]].values[0].T\n",
    "    new_df = pd.DataFrame(data = new_data_dict)\n",
    "  \n",
    "    if not(y_per_h is None):\n",
    "        y_per_h = pd.concat([y_per_h, new_df])\n",
    "        print(f'Se agregaron {i*672} filas de {y_tmp.shape[0]*672}')\n",
    "    else:\n",
    "        y_per_h = new_df\n",
    "\n",
    "y_per_h.to_csv('../raw_data/y_per_h.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5825be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidp/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "X_per_h = pd.read_csv('../raw_data/X_per_h.csv', index_col = 0)\n",
    "y_per_h = pd.read_csv('../raw_data/y_per_h.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e42ed5",
   "metadata": {},
   "source": [
    "### Analizamos la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0b09e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bajamos la cantidad de filas para no sobrepasar la RAM\n",
    "data_per_h = pd.concat([X_per_h, y_per_h], axis = 1)\n",
    "data_per_h = data_per_h.head(500_000)\n",
    "\n",
    "X_per_h = data_per_h[X_per_h.columns]\n",
    "y_per_h = data_per_h[y_per_h.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "43d86616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0000\n",
       "1      1.6818\n",
       "2      1.6818\n",
       "3      1.6818\n",
       "4      1.6818\n",
       "       ...   \n",
       "27     7.0426\n",
       "28     7.0426\n",
       "29     7.0426\n",
       "30     7.0426\n",
       "31    43.5240\n",
       "Length: 500000, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_per_h_total = y_per_h.sum(axis=1)\n",
    "y_per_h_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec988a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_per_h)\n",
    "columns = X_per_h.columns\n",
    "\n",
    "X_scaled = pd.DataFrame(scaler.transform(X_per_h), columns = columns)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(X_scaled).corr(), cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ba6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cols= ['ac_mask',\n",
    " 'ventilation_mask',\n",
    " 'occupancy',\n",
    " 'pc_on_mask',\n",
    " 'DNI',\n",
    " 'IBEAM_H',\n",
    " 'IBEAM_N',\n",
    " 'IDIFF_H',\n",
    " 'IGLOB_H'\n",
    " ]\n",
    "sns.heatmap(pd.DataFrame(X_per_h[corr_cols]).corr(), cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a000cca0",
   "metadata": {},
   "source": [
    "Correlaciones relevantes:\n",
    "\n",
    "*   pc_on_mask\n",
    "*   occupancy\n",
    "<br>\n",
    "\n",
    "*   IBEAM_N\n",
    "*   IGLOB_H\n",
    "*   IBEAM_H\n",
    "*   DNI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb886cc0",
   "metadata": {},
   "source": [
    "### Aplicamos PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = pca.transform(X_scaled)\n",
    "X_proj = pd.DataFrame(X_proj, columns=[f'PC{i}' for i in range(1, 36)])\n",
    "\n",
    "sns.heatmap(X_proj.corr(), cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00708700",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb1bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component'); plt.ylabel('% explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.ylim(ymin=0)\n",
    "plt.title('cumulated share of explained variance')\n",
    "plt.xlabel('# of principal component used');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3eb4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducimos la cantidad de componentes a 24\n",
    "pca = PCA(n_components=24).fit(X_per_h)\n",
    "\n",
    "X_proj24 = pd.DataFrame(pca.fit_transform(X_per_h), columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24'])\n",
    "X_proj24.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df6e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from modelo_energetico.scaler import MultiScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Probamos con SGDRegressor en Gridsearch\n",
    "pipe = Pipeline([\n",
    "          (\"scaling\" , MultiScaler(scaler = \"RobustScaler\")),\n",
    "        (\"model\", SGDRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'scaling__scaler' : [StandardScaler(), RobustScaler(), MinMaxScaler() ],     \n",
    "    'model__loss': ['huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'model__alpha': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'model__l1_ratio': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid= params, \n",
    "                    cv=5,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1,\n",
    "                    scoring = 'r2'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4aebc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      X_proj24, y_per_h_total, test_size=0.3, random_state=42)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "  \n",
    "start = datetime.now()\n",
    "best_estimator = grid.best_estimator_.fit(X_train, y_train)\n",
    "stop = datetime.now()\n",
    "score = best_estimator.score(X_test, y_test)\n",
    "time = (stop - start).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(score, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775effa",
   "metadata": {},
   "source": [
    "r2 = 0.704 \\\n",
    "tiempo = 4 seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a858ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos columna con consumo en hora anterior\n",
    "y_per_h_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_per_h_total_offset = y_per_h_total.shift(periods= 1, fill_value= 0)\n",
    "y_per_h_total_offset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_per_h['Prev_Q'] = y_per_h_total_offset\n",
    "X_per_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82136741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos PCA nuevamente\n",
    "scaler.fit(X_per_h)\n",
    "columns = X_per_h.columns\n",
    "X_scaled = pd.DataFrame(scaler.transform(X_per_h), columns = columns)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "X_proj = pca.transform(X_scaled)\n",
    "X_proj = pd.DataFrame(X_proj, columns=[f'PC{i}' for i in range(1, 37)])\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component'); plt.ylabel('% explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.ylim(ymin=0)\n",
    "plt.title('cumulated share of explained variance')\n",
    "plt.xlabel('# of principal component used');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e91809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducimos la cantidad de componentes a 28\n",
    "pca = PCA(n_components=28).fit(X_per_h)\n",
    "\n",
    "X_proj28 = pd.DataFrame(pca.fit_transform(X_per_h), columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25', 'PC26', 'PC27', 'PC28'])\n",
    "X_proj28.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos nuevamente el SGDRegressor\n",
    "pipe = Pipeline([\n",
    "          (\"scaling\" , MultiScaler(scaler = \"RobustScaler\")),\n",
    "        (\"model\", SGDRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'scaling__scaler' : [StandardScaler(), RobustScaler(), MinMaxScaler() ],     \n",
    "    'model__loss': ['huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'model__alpha': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'model__l1_ratio': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid= params, \n",
    "                    cv=5,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1,\n",
    "                    scoring = 'r2'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451aeeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      X_proj28, y_per_h_total, test_size=0.3, random_state=42)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "  \n",
    "start = datetime.now()\n",
    "best_estimator = grid.best_estimator_.fit(X_train, y_train)\n",
    "stop = datetime.now()\n",
    "score = best_estimator.score(X_test, y_test)\n",
    "time = (stop - start).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e50c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "(score, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0518fc",
   "metadata": {},
   "source": [
    "r2 = 0.707 \\\n",
    "tiempo = 5 seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d97bb8a",
   "metadata": {},
   "source": [
    "## Escenario - Dataset con rangos de tiempo por fila"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ce6c0",
   "metadata": {},
   "source": [
    "### Armamos datasets para distintos períodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f885575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidp/code/rcister01/modelo_energetico/modelo_energetico/col_reductor.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[f'Q_{i}'] = np.zeros(dataframe.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_0</th>\n",
       "      <th>Q_1</th>\n",
       "      <th>Q_2</th>\n",
       "      <th>Q_3</th>\n",
       "      <th>Q_4</th>\n",
       "      <th>Q_5</th>\n",
       "      <th>Q_6</th>\n",
       "      <th>Q_7</th>\n",
       "      <th>Q_8</th>\n",
       "      <th>Q_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Q_662</th>\n",
       "      <th>Q_663</th>\n",
       "      <th>Q_664</th>\n",
       "      <th>Q_665</th>\n",
       "      <th>Q_666</th>\n",
       "      <th>Q_667</th>\n",
       "      <th>Q_668</th>\n",
       "      <th>Q_669</th>\n",
       "      <th>Q_670</th>\n",
       "      <th>Q_671</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6818</td>\n",
       "      <td>1.6818</td>\n",
       "      <td>1.6818</td>\n",
       "      <td>1.6818</td>\n",
       "      <td>1.6818</td>\n",
       "      <td>1.6818</td>\n",
       "      <td>35.4240</td>\n",
       "      <td>38.7781</td>\n",
       "      <td>38.7781</td>\n",
       "      <td>...</td>\n",
       "      <td>88.8217</td>\n",
       "      <td>95.9126</td>\n",
       "      <td>102.8931</td>\n",
       "      <td>102.8037</td>\n",
       "      <td>48.4459</td>\n",
       "      <td>12.9279</td>\n",
       "      <td>1.6818</td>\n",
       "      <td>5.1005</td>\n",
       "      <td>11.4541</td>\n",
       "      <td>8.6840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>44.8740</td>\n",
       "      <td>44.8740</td>\n",
       "      <td>44.8740</td>\n",
       "      <td>...</td>\n",
       "      <td>23.4454</td>\n",
       "      <td>21.4724</td>\n",
       "      <td>22.6562</td>\n",
       "      <td>23.8400</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "      <td>2.9261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>95.0924</td>\n",
       "      <td>92.1329</td>\n",
       "      <td>87.3977</td>\n",
       "      <td>...</td>\n",
       "      <td>78.1176</td>\n",
       "      <td>77.4426</td>\n",
       "      <td>79.1440</td>\n",
       "      <td>82.4168</td>\n",
       "      <td>84.3485</td>\n",
       "      <td>13.3174</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>3.6095</td>\n",
       "      <td>3.6095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>50.6268</td>\n",
       "      <td>49.7390</td>\n",
       "      <td>48.2592</td>\n",
       "      <td>...</td>\n",
       "      <td>52.7971</td>\n",
       "      <td>52.4025</td>\n",
       "      <td>52.0079</td>\n",
       "      <td>52.4025</td>\n",
       "      <td>52.7971</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>7.2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>10.2298</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2297</td>\n",
       "      <td>74.8921</td>\n",
       "      <td>78.2945</td>\n",
       "      <td>78.5638</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>6.4811</td>\n",
       "      <td>13.5212</td>\n",
       "      <td>30.9471</td>\n",
       "      <td>25.7187</td>\n",
       "      <td>12.1803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q_0     Q_1     Q_2     Q_3     Q_4     Q_5     Q_6      Q_7      Q_8  \\\n",
       "0  0.0  1.6818  1.6818  1.6818  1.6818  1.6818  1.6818  35.4240  38.7781   \n",
       "1  0.0  2.9261  2.9261  2.9261  2.9261  2.9261  2.9261  44.8740  44.8740   \n",
       "2  0.0  3.6095  3.6095  3.6095  3.6095  3.6095  3.6095  95.0924  92.1329   \n",
       "3  0.0  7.2196  7.2196  7.2196  7.2196  7.2196  7.2196  50.6268  49.7390   \n",
       "4  0.0  6.4811  6.4811  6.4811  6.4811  6.4811  6.4811   6.4811   6.4811   \n",
       "\n",
       "       Q_9  ...    Q_662    Q_663     Q_664     Q_665    Q_666    Q_667  \\\n",
       "0  38.7781  ...  88.8217  95.9126  102.8931  102.8037  48.4459  12.9279   \n",
       "1  44.8740  ...  23.4454  21.4724   22.6562   23.8400   2.9261   2.9261   \n",
       "2  87.3977  ...  78.1176  77.4426   79.1440   82.4168  84.3485  13.3174   \n",
       "3  48.2592  ...  52.7971  52.4025   52.0079   52.4025  52.7971   7.2196   \n",
       "4  10.2298  ...  70.2297  74.8921   78.2945   78.5638   6.4811   6.4811   \n",
       "\n",
       "     Q_668    Q_669    Q_670    Q_671  \n",
       "0   1.6818   5.1005  11.4541   8.6840  \n",
       "1   2.9261   2.9261   2.9261   2.9261  \n",
       "2   3.6095   3.6095   3.6095   3.6095  \n",
       "3   7.2196   7.2196   7.2196   7.2196  \n",
       "4  13.5212  30.9471  25.7187  12.1803  \n",
       "\n",
       "[5 rows x 672 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelo_energetico.col_reductor import total_q_hour\n",
    "\n",
    "# El Target (Q) lo trabajamos sumando todos los tipos (Q global)\n",
    "y = total_q_hour(y)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370f4693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidp/code/rcister01/modelo_energetico/modelo_energetico/col_reductor.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[f'{column}_{i}'] = np.zeros(dataframe.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from modelo_energetico.col_reductor import reduce_columns_period_avg, reduce_columns_period_sum\n",
    "\n",
    "X_reduced_train = {}\n",
    "y_reduced_train = {}\n",
    "X_reduced_test = {}\n",
    "y_reduced_test = {}\n",
    "\n",
    "for div in [1, 2, 4, 7, 14, 28]:\n",
    "    X_reduced = pd.concat([X[columns_c], reduce_columns_period_avg(X, columns_s, div)], axis = 1)\n",
    "    y_reduced = reduce_columns_period_sum(y, ['Q'], div)\n",
    "\n",
    "    X_reduced_train[div], X_reduced_test[div], y_reduced_train[div], y_reduced_test[div] = train_test_split(X_reduced, y_reduced, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a511373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=y_reduced_train[28])\n",
    "plt.title('Distribución de los Consumos Mensuales');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d2ab7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=X_reduced_train[28]['TAMB_0'])\n",
    "plt.title('Distribución de las Temperaturas Mensuales');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "744e33bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5250.000000\n",
       "mean       16.899128\n",
       "std         4.482166\n",
       "min         9.890476\n",
       "25%        12.704315\n",
       "50%        17.136756\n",
       "75%        20.713839\n",
       "max        23.247024\n",
       "Name: TAMB_0, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced_train[28]['TAMB_0'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c979da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_0</th>\n",
       "      <th>T_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7179</th>\n",
       "      <td>29650.1766</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>30924.1840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>25277.1535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>22236.5015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>31469.5410</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Q_0  T_level\n",
       "7179  29650.1766        2\n",
       "6054  30924.1840        2\n",
       "7269  25277.1535        1\n",
       "4866  22236.5015        2\n",
       "3593  31469.5410        3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reduced_train[28]['T_level'] = X_reduced_train[28]['TAMB_0'].apply(lambda x: 0 if x < 12.636607 else (1 if x < 17.136756 else (2 if x < 20.713839 else 3)))\n",
    "y_reduced_train[28].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e1e6589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Distribución de Consumo Mensual según Nivel de T°')\n",
    "sns.histplot(data=y_reduced_train[28], x=\"Q_0\", hue=\"T_level\", stat= 'density', element='step');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218eeb69",
   "metadata": {},
   "source": [
    "### Probamos SGDRegressor con distintos períodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48194005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "pipe = Pipeline([\n",
    "          (\"scaling\" , MultiScaler(scaler = \"RobustScaler\")),\n",
    "        (\"model\", MultiOutputRegressor(estimator = SGDRegressor()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pipe.get_params().keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'scaling__scaler' : [StandardScaler(), RobustScaler(), MinMaxScaler() ],     \n",
    "    'model__estimator__loss': ['huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'model__estimator__alpha': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'model__estimator__l1_ratio': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid= params, \n",
    "                    cv=5,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1,\n",
    "                    scoring = 'r2'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68054b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "results = {}\n",
    "\n",
    "for div in [28, 14, 7]:\n",
    "    grid.fit(X_reduced_train[div], y_reduced_train[div])\n",
    "  \n",
    "    start = datetime.now()\n",
    "    best_estimator = grid.best_estimator_.fit(X_reduced_train[div], y_reduced_train[div])\n",
    "    stop = datetime.now()\n",
    "    \n",
    "    best_score = best_estimator.score(X_reduced_test[div], y_reduced_test[div])\n",
    "    time = (stop - start).seconds\n",
    "  \n",
    "    models[div] = best_estimator\n",
    "    results[div] = (best_score, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de673d4f",
   "metadata": {},
   "source": [
    "7 days --> r2= 0.9475 (0 secs): \\\n",
    "1.   alpha= 0.0001\n",
    "2.   l1_ratio= 0.01\n",
    "3.   loss= squared_epsilon_insensitive \\\n",
    "\n",
    "14 days --> r2= 0.9527 (0 secs): \\\n",
    "1.   alpha= 0.0001\n",
    "2.   l1_ratio= 0.1\n",
    "3.   loss= squared_epsilon_insensitive\n",
    "\n",
    "28 days --> r2= 0.9620 (0 secs): \\\n",
    "1.   alpha= 0.0001\n",
    "2.   l1_ratio= 0.1\n",
    "3.   loss= squared_epsilon_insensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a05dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con 28 días de rango\n",
    "pipe = Pipeline([\n",
    "          (\"scaling\" , StandardScaler()),\n",
    "        (\"model\", MultiOutputRegressor(estimator = SGDRegressor()))\n",
    "])\n",
    "\n",
    "start = datetime.now()\n",
    "model = pipe.fit(X_reduced_train[1], y_reduced_train[1])\n",
    "stop = datetime.now()\n",
    "\n",
    "time = (stop - start).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c63a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_reduced_test[1], y_reduced_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b93ff",
   "metadata": {},
   "source": [
    "1 day --> r2= 0.9346 (7 secs): \\\n",
    "1.   alpha= 0.0001\n",
    "2.   l1_ratio= 0.15\n",
    "3.   loss= squared_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2456171",
   "metadata": {},
   "source": [
    "## Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69d197",
   "metadata": {},
   "source": [
    "### Escenario - Dataset con rangos de tiempo por fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1b0904b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos sobre el escenario de consumo mensual (período de 28 días)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_reduced_train[28])\n",
    "X_train_scaled = scaler.transform(X_reduced_train[28])\n",
    "X_test_scaled = scaler.transform(X_reduced_test[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e20fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_vanilla_nn(n_neurons, input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(n_neurons[0], activation='relu', input_dim=input_dim))\n",
    "    for i in range(1, len(n_neurons)):\n",
    "        model.add(layers.Dense(n_neurons[i], activation='relu'))\n",
    "    model.add(layers.Dense(output_dim, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5ea1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "output_dim = y_reduced_train[28].shape[1]\n",
    "nn = (150, 100, 50, 50, 25, 10)\n",
    "\n",
    "model = KerasRegressor(init_vanilla_nn, n_neurons=nn, input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a328a164",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 100602440.0000 - mae: 5251.7266 - val_loss: 346669952.0000 - val_mae: 13827.3945\n",
      "Epoch 2/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 2407234.7500 - mae: 874.2605 - val_loss: 345245504.0000 - val_mae: 13555.5605\n",
      "Epoch 3/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1628535.5000 - mae: 719.4095 - val_loss: 344781600.0000 - val_mae: 13463.8252\n",
      "Epoch 4/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1225825.5000 - mae: 625.0781 - val_loss: 344496544.0000 - val_mae: 13386.5186\n",
      "Epoch 5/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 980986.8125 - mae: 560.5739 - val_loss: 344316160.0000 - val_mae: 13341.1270\n",
      "Epoch 6/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 814113.8125 - mae: 507.8325 - val_loss: 344051840.0000 - val_mae: 13300.1982\n",
      "Epoch 7/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 704097.9375 - mae: 473.3026 - val_loss: 343963616.0000 - val_mae: 13260.5420\n",
      "Epoch 8/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 628569.5000 - mae: 447.4264 - val_loss: 343945408.0000 - val_mae: 13247.7178\n",
      "Epoch 9/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 539471.7500 - mae: 414.7711 - val_loss: 343864480.0000 - val_mae: 13272.1729\n",
      "Epoch 10/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 504538.3438 - mae: 402.5943 - val_loss: 343839840.0000 - val_mae: 13207.8867\n",
      "Epoch 11/1000\n",
      "329/329 [==============================] - ETA: 0s - loss: 462780.7188 - mae: 384.37 - 1s 2ms/step - loss: 462780.7188 - mae: 384.3756 - val_loss: 343882848.0000 - val_mae: 13184.4434\n",
      "Epoch 12/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 440058.8750 - mae: 380.4064 - val_loss: 343826304.0000 - val_mae: 13173.9707\n",
      "Epoch 13/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 391714.5625 - mae: 357.6732 - val_loss: 343685536.0000 - val_mae: 13188.0117\n",
      "Epoch 14/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 377348.6562 - mae: 351.7304 - val_loss: 343726656.0000 - val_mae: 13173.9355\n",
      "Epoch 15/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 362241.8125 - mae: 345.1378 - val_loss: 343617504.0000 - val_mae: 13136.3242\n",
      "Epoch 16/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 353318.8125 - mae: 342.5674 - val_loss: 343369856.0000 - val_mae: 13164.6289\n",
      "Epoch 17/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 348455.5938 - mae: 341.2606 - val_loss: 344046368.0000 - val_mae: 13131.9336\n",
      "Epoch 18/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 320605.4062 - mae: 325.4078 - val_loss: 343691936.0000 - val_mae: 13130.6787\n",
      "Epoch 19/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 302573.9688 - mae: 318.1150 - val_loss: 343471616.0000 - val_mae: 13145.0254\n",
      "Epoch 20/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 318021.8438 - mae: 323.3712 - val_loss: 344090432.0000 - val_mae: 13134.4219\n",
      "Epoch 21/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 304445.7188 - mae: 321.0225 - val_loss: 343647648.0000 - val_mae: 13153.7803\n",
      "Epoch 22/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 281934.4688 - mae: 305.2077 - val_loss: 343928256.0000 - val_mae: 13136.0527\n",
      "Epoch 23/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 288074.4688 - mae: 312.7410 - val_loss: 342683584.0000 - val_mae: 13099.0273\n",
      "Epoch 24/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 284661.6875 - mae: 308.1214 - val_loss: 343484736.0000 - val_mae: 13108.6230\n",
      "Epoch 25/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 262765.1250 - mae: 294.7922 - val_loss: 343558080.0000 - val_mae: 13138.8965\n",
      "Epoch 26/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 272843.0312 - mae: 302.9208 - val_loss: 344062112.0000 - val_mae: 13126.2422\n",
      "Epoch 27/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 260981.8594 - mae: 296.8929 - val_loss: 342848864.0000 - val_mae: 13105.9805\n",
      "Epoch 28/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 262267.8438 - mae: 297.5454 - val_loss: 343405888.0000 - val_mae: 13168.8057\n",
      "Epoch 29/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 251762.3281 - mae: 290.1104 - val_loss: 343435616.0000 - val_mae: 13100.4326\n",
      "Epoch 30/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 252741.2344 - mae: 291.6899 - val_loss: 342990080.0000 - val_mae: 13077.1113\n",
      "Epoch 31/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 248458.5312 - mae: 291.3018 - val_loss: 342806592.0000 - val_mae: 13081.0957\n",
      "Epoch 32/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 238588.0469 - mae: 283.9065 - val_loss: 344531648.0000 - val_mae: 13190.3682\n",
      "Epoch 33/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 238089.3125 - mae: 285.4816 - val_loss: 343819456.0000 - val_mae: 13085.0840\n",
      "Epoch 34/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 249017.1562 - mae: 293.3037 - val_loss: 343498432.0000 - val_mae: 13095.3203\n",
      "Epoch 35/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 218866.6875 - mae: 269.3951 - val_loss: 342975200.0000 - val_mae: 13067.4697\n",
      "Epoch 36/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 228099.2500 - mae: 276.5050 - val_loss: 343214720.0000 - val_mae: 13094.1641\n",
      "Epoch 37/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 231309.6562 - mae: 279.1165 - val_loss: 343676608.0000 - val_mae: 13119.8838\n",
      "Epoch 38/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 219964.9219 - mae: 271.6734 - val_loss: 343492448.0000 - val_mae: 13080.3330\n",
      "Epoch 39/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 218836.0625 - mae: 269.3998 - val_loss: 343181696.0000 - val_mae: 13120.5156\n",
      "Epoch 40/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 234219.1562 - mae: 282.8513 - val_loss: 343663744.0000 - val_mae: 13083.4014\n",
      "Epoch 41/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 215215.2188 - mae: 272.5456 - val_loss: 343171008.0000 - val_mae: 13075.3320\n",
      "Epoch 42/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 222247.0312 - mae: 272.7437 - val_loss: 343235744.0000 - val_mae: 13071.2656\n",
      "Epoch 43/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 217490.2344 - mae: 274.2057 - val_loss: 344159872.0000 - val_mae: 13085.8037\n",
      "Epoch 44/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 208781.7188 - mae: 266.1021 - val_loss: 343646944.0000 - val_mae: 13090.8691\n",
      "Epoch 45/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 213842.6094 - mae: 268.8031 - val_loss: 342775008.0000 - val_mae: 13088.6367\n",
      "Epoch 46/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 209294.9531 - mae: 266.3585 - val_loss: 343899200.0000 - val_mae: 13105.6387\n",
      "Epoch 47/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 201450.0625 - mae: 260.9394 - val_loss: 342704704.0000 - val_mae: 13068.8643\n",
      "Epoch 48/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 216531.6094 - mae: 271.1883 - val_loss: 343248960.0000 - val_mae: 13058.5059\n",
      "Epoch 49/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 220467.0000 - mae: 275.0214 - val_loss: 343541728.0000 - val_mae: 13067.9775\n",
      "Epoch 50/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 207130.2812 - mae: 263.8698 - val_loss: 343891648.0000 - val_mae: 13089.7822\n",
      "Epoch 51/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 208982.3750 - mae: 265.4482 - val_loss: 343906528.0000 - val_mae: 13079.5205\n",
      "Epoch 52/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 192101.0469 - mae: 254.3073 - val_loss: 343927232.0000 - val_mae: 13078.8740\n",
      "Epoch 53/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 198869.5312 - mae: 262.2449 - val_loss: 343384160.0000 - val_mae: 13069.8350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 192106.7656 - mae: 254.2507 - val_loss: 343697600.0000 - val_mae: 13067.9268\n",
      "Epoch 55/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 190569.4844 - mae: 254.2661 - val_loss: 342978624.0000 - val_mae: 13148.5889\n",
      "Epoch 56/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 209058.2969 - mae: 267.2036 - val_loss: 343076640.0000 - val_mae: 13059.3008\n",
      "Epoch 57/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 182749.0312 - mae: 248.8031 - val_loss: 343420864.0000 - val_mae: 13124.2451\n",
      "Epoch 58/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 206966.9062 - mae: 266.6868 - val_loss: 343291424.0000 - val_mae: 13072.0264\n",
      "Epoch 59/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 184114.8438 - mae: 250.4852 - val_loss: 343603104.0000 - val_mae: 13061.9238\n",
      "Epoch 60/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 181231.9531 - mae: 246.9509 - val_loss: 343308544.0000 - val_mae: 13063.6064\n",
      "Epoch 61/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 187340.9688 - mae: 252.2162 - val_loss: 342753632.0000 - val_mae: 13058.8623\n",
      "Epoch 62/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 187699.1562 - mae: 251.8012 - val_loss: 343292320.0000 - val_mae: 13064.7295\n",
      "Epoch 63/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 177628.3438 - mae: 246.8504 - val_loss: 343703968.0000 - val_mae: 13090.5977\n",
      "Epoch 64/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 180061.0156 - mae: 248.3506 - val_loss: 343689408.0000 - val_mae: 13082.0244\n",
      "Epoch 65/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 189349.0156 - mae: 253.7508 - val_loss: 344089792.0000 - val_mae: 13084.1660\n",
      "Epoch 66/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 171986.7188 - mae: 242.3273 - val_loss: 343804736.0000 - val_mae: 13086.5869\n",
      "Epoch 67/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 171510.1875 - mae: 241.2047 - val_loss: 343114784.0000 - val_mae: 13082.6436\n",
      "Epoch 68/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 181373.1406 - mae: 247.7074 - val_loss: 343164544.0000 - val_mae: 13095.3965\n",
      "Epoch 69/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 170122.7344 - mae: 239.7279 - val_loss: 343570112.0000 - val_mae: 13061.7324\n",
      "Epoch 70/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 183564.7344 - mae: 250.7666 - val_loss: 343743296.0000 - val_mae: 13112.2549\n",
      "Epoch 71/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 167223.9844 - mae: 240.5495 - val_loss: 343408480.0000 - val_mae: 13057.8945\n",
      "Epoch 72/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 178006.5000 - mae: 244.1333 - val_loss: 343705568.0000 - val_mae: 13067.3906\n",
      "Epoch 73/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 174789.1094 - mae: 245.0582 - val_loss: 343946400.0000 - val_mae: 13086.7422\n",
      "Epoch 74/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 167372.1406 - mae: 237.5402 - val_loss: 342760768.0000 - val_mae: 13054.1016\n",
      "Epoch 75/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 161020.9844 - mae: 233.5347 - val_loss: 342928864.0000 - val_mae: 13066.2920\n",
      "Epoch 76/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 168331.0469 - mae: 239.0312 - val_loss: 342885600.0000 - val_mae: 13047.4482\n",
      "Epoch 77/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 158657.1875 - mae: 231.9550 - val_loss: 343236608.0000 - val_mae: 13057.5137\n",
      "Epoch 78/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 171236.9688 - mae: 240.3798 - val_loss: 344192640.0000 - val_mae: 13114.7656\n",
      "Epoch 79/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 169669.5469 - mae: 237.5369 - val_loss: 343766304.0000 - val_mae: 13084.5664\n",
      "Epoch 80/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 158316.8438 - mae: 229.5407 - val_loss: 344515040.0000 - val_mae: 13096.6562\n",
      "Epoch 81/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 173543.9531 - mae: 243.3459 - val_loss: 342385984.0000 - val_mae: 13046.0400\n",
      "Epoch 82/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 170698.8906 - mae: 241.5364 - val_loss: 342902336.0000 - val_mae: 13079.3604\n",
      "Epoch 83/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 163113.0469 - mae: 236.1079 - val_loss: 343675392.0000 - val_mae: 13065.5723\n",
      "Epoch 84/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 161733.9688 - mae: 235.0465 - val_loss: 343477376.0000 - val_mae: 13059.7080\n",
      "Epoch 85/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 160741.1719 - mae: 233.1065 - val_loss: 342824480.0000 - val_mae: 13058.5283\n",
      "Epoch 86/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 148524.5312 - mae: 222.4032 - val_loss: 343390944.0000 - val_mae: 13056.4385\n",
      "Epoch 87/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 161000.1875 - mae: 233.7521 - val_loss: 343414464.0000 - val_mae: 13078.0586\n",
      "Epoch 88/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 148444.1406 - mae: 223.6871 - val_loss: 343637792.0000 - val_mae: 13067.8730\n",
      "Epoch 89/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 155118.1094 - mae: 228.8858 - val_loss: 343635648.0000 - val_mae: 13117.5459\n",
      "Epoch 90/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 152304.5469 - mae: 226.9743 - val_loss: 343665728.0000 - val_mae: 13068.4990\n",
      "Epoch 91/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 147040.4062 - mae: 223.7466 - val_loss: 343399200.0000 - val_mae: 13051.2490\n",
      "Epoch 92/1000\n",
      "157/329 [=============>................] - ETA: 0s - loss: 149345.6875 - mae: 224.9289"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23060/115470395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train_scaled, y_reduced_train[28],\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_reduced_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           epochs=1000)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1092\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2174\u001b[0m         \u001b[0moutputs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2176\u001b[0;31m     ret = nest.pack_sequence_as(self._func_graph.structured_outputs,\n\u001b[0m\u001b[1;32m   2177\u001b[0m                                 outputs_list, expand_composites=True)\n\u001b[1;32m   2178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_reduced_train[28],\n",
    "          validation_data=(X_test_scaled, y_reduced_test[28]), \n",
    "          batch_size=16,\n",
    "          epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0f5ba2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vanilla_nn_w_dropout(n_neurons, input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(n_neurons[0], activation='relu', input_dim=input_dim))\n",
    "    model.add(layers.Dropout(.2))\n",
    "    for i in range(1, len(n_neurons)):\n",
    "        model.add(layers.Dense(n_neurons[i], activation='relu'))\n",
    "    model.add(layers.Dense(output_dim, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f19330de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(init_vanilla_nn_w_dropout, n_neurons=nn, input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5749a78f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 94739792.0000 - mae: 4634.9253 - val_loss: 347037248.0000 - val_mae: 13880.3525\n",
      "Epoch 2/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 2520939.7500 - mae: 890.8455 - val_loss: 345414784.0000 - val_mae: 13598.2949\n",
      "Epoch 3/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1723432.7500 - mae: 737.9659 - val_loss: 344980224.0000 - val_mae: 13508.7148\n",
      "Epoch 4/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1341169.2500 - mae: 649.5721 - val_loss: 344688384.0000 - val_mae: 13407.2334\n",
      "Epoch 5/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1074711.5000 - mae: 583.0770 - val_loss: 344517792.0000 - val_mae: 13395.5234\n",
      "Epoch 6/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 895586.3125 - mae: 535.3611 - val_loss: 344210048.0000 - val_mae: 13312.2334\n",
      "Epoch 7/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 778642.7500 - mae: 498.7522 - val_loss: 343969888.0000 - val_mae: 13286.2021\n",
      "Epoch 8/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 675565.8125 - mae: 466.5093 - val_loss: 343962016.0000 - val_mae: 13294.4111\n",
      "Epoch 9/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 609474.7500 - mae: 443.7041 - val_loss: 343933568.0000 - val_mae: 13239.4707\n",
      "Epoch 10/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 539173.6875 - mae: 415.3067 - val_loss: 343866240.0000 - val_mae: 13239.5664\n",
      "Epoch 11/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 502547.1250 - mae: 402.8521 - val_loss: 343743776.0000 - val_mae: 13192.2480\n",
      "Epoch 12/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 462631.1562 - mae: 385.5108 - val_loss: 343611104.0000 - val_mae: 13195.6924\n",
      "Epoch 13/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 420001.6875 - mae: 366.2905 - val_loss: 343911552.0000 - val_mae: 13195.9473\n",
      "Epoch 14/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 412155.0625 - mae: 365.5887 - val_loss: 343773792.0000 - val_mae: 13156.3066\n",
      "Epoch 15/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 390796.9375 - mae: 355.6687 - val_loss: 343856512.0000 - val_mae: 13157.8848\n",
      "Epoch 16/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 353323.0938 - mae: 338.9558 - val_loss: 343599808.0000 - val_mae: 13165.4092\n",
      "Epoch 17/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 351303.5938 - mae: 339.3641 - val_loss: 343821696.0000 - val_mae: 13155.5791\n",
      "Epoch 18/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 347335.3125 - mae: 335.7160 - val_loss: 343378208.0000 - val_mae: 13123.8457\n",
      "Epoch 19/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 327449.2188 - mae: 326.5639 - val_loss: 343665056.0000 - val_mae: 13157.5830\n",
      "Epoch 20/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 309917.4375 - mae: 316.2151 - val_loss: 343877248.0000 - val_mae: 13134.8662\n",
      "Epoch 21/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 286599.5000 - mae: 307.2494 - val_loss: 343699328.0000 - val_mae: 13136.5635\n",
      "Epoch 22/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 317989.7188 - mae: 321.2675 - val_loss: 343572320.0000 - val_mae: 13123.1006\n",
      "Epoch 23/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 284777.9375 - mae: 303.5598 - val_loss: 343449024.0000 - val_mae: 13104.0742\n",
      "Epoch 24/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 264148.1562 - mae: 293.1965 - val_loss: 343698944.0000 - val_mae: 13151.1348\n",
      "Epoch 25/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 270360.6562 - mae: 295.1544 - val_loss: 343571136.0000 - val_mae: 13115.3184\n",
      "Epoch 26/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 259990.2344 - mae: 289.4938 - val_loss: 343444992.0000 - val_mae: 13119.7793\n",
      "Epoch 27/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 266348.0312 - mae: 294.2686 - val_loss: 343741024.0000 - val_mae: 13115.6523\n",
      "Epoch 28/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 256783.5625 - mae: 290.1849 - val_loss: 343298816.0000 - val_mae: 13096.1055\n",
      "Epoch 29/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 251867.5781 - mae: 286.5663 - val_loss: 343323136.0000 - val_mae: 13137.0781\n",
      "Epoch 30/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 237920.4531 - mae: 279.0244 - val_loss: 343499360.0000 - val_mae: 13134.4219\n",
      "Epoch 31/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 243625.6875 - mae: 280.9138 - val_loss: 343551008.0000 - val_mae: 13125.6787\n",
      "Epoch 32/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 226398.3594 - mae: 270.7021 - val_loss: 343475680.0000 - val_mae: 13101.4102\n",
      "Epoch 33/1000\n",
      "329/329 [==============================] - ETA: 0s - loss: 223888.3438 - mae: 269.74 - 1s 2ms/step - loss: 223253.3594 - mae: 269.3961 - val_loss: 343385696.0000 - val_mae: 13096.1758\n",
      "Epoch 34/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 220192.5781 - mae: 267.6307 - val_loss: 343546240.0000 - val_mae: 13098.4131\n",
      "Epoch 35/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 219680.1094 - mae: 267.9446 - val_loss: 343296032.0000 - val_mae: 13081.4082\n",
      "Epoch 36/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 243966.4688 - mae: 278.5088 - val_loss: 343475872.0000 - val_mae: 13104.9404\n",
      "Epoch 37/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 212778.6250 - mae: 263.8960 - val_loss: 343288064.0000 - val_mae: 13084.0332\n",
      "Epoch 38/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 224818.6406 - mae: 270.3642 - val_loss: 343461760.0000 - val_mae: 13106.5430\n",
      "Epoch 39/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 211651.0156 - mae: 262.5406 - val_loss: 343412704.0000 - val_mae: 13094.0439\n",
      "Epoch 40/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 208135.0781 - mae: 260.8612 - val_loss: 343473536.0000 - val_mae: 13087.5645\n",
      "Epoch 41/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 202946.2188 - mae: 256.1505 - val_loss: 343630016.0000 - val_mae: 13095.3252\n",
      "Epoch 42/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 202289.3281 - mae: 256.2666 - val_loss: 343539904.0000 - val_mae: 13116.9736\n",
      "Epoch 43/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 197554.4844 - mae: 251.0835 - val_loss: 343544192.0000 - val_mae: 13110.7471\n",
      "Epoch 44/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 193330.5000 - mae: 249.1485 - val_loss: 343508992.0000 - val_mae: 13085.9658\n",
      "Epoch 45/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 185611.8281 - mae: 244.6701 - val_loss: 343503616.0000 - val_mae: 13135.5312\n",
      "Epoch 46/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 190188.0938 - mae: 248.8100 - val_loss: 343421024.0000 - val_mae: 13095.2529\n",
      "Epoch 47/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 199689.5000 - mae: 252.6502 - val_loss: 343576480.0000 - val_mae: 13122.6963\n",
      "Epoch 48/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 191840.2188 - mae: 248.6656 - val_loss: 343573856.0000 - val_mae: 13103.7227\n",
      "Epoch 49/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 183818.5625 - mae: 242.3403 - val_loss: 343396160.0000 - val_mae: 13084.9551\n",
      "Epoch 50/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 215049.6250 - mae: 260.4187 - val_loss: 343719808.0000 - val_mae: 13175.7617\n",
      "Epoch 51/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 205454.0625 - mae: 257.0901 - val_loss: 343515392.0000 - val_mae: 13077.4814\n",
      "Epoch 52/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 183013.5000 - mae: 242.6537 - val_loss: 343505952.0000 - val_mae: 13083.9678\n",
      "Epoch 53/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 181091.2656 - mae: 240.4839 - val_loss: 343581024.0000 - val_mae: 13107.5488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 171750.3750 - mae: 235.4542 - val_loss: 343449408.0000 - val_mae: 13096.2188\n",
      "Epoch 55/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 183762.1562 - mae: 243.1798 - val_loss: 343676352.0000 - val_mae: 13080.0664\n",
      "Epoch 56/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 188210.3281 - mae: 245.7271 - val_loss: 343548384.0000 - val_mae: 13113.4326\n",
      "Epoch 57/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 170247.0781 - mae: 233.9823 - val_loss: 343549664.0000 - val_mae: 13101.6914\n",
      "Epoch 58/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 174750.5156 - mae: 236.8162 - val_loss: 343530784.0000 - val_mae: 13087.6699\n",
      "Epoch 59/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 183230.8906 - mae: 241.4745 - val_loss: 343452224.0000 - val_mae: 13079.8838\n",
      "Epoch 60/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 165588.8906 - mae: 232.3571 - val_loss: 343402880.0000 - val_mae: 13084.2930\n",
      "Epoch 61/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 164696.6250 - mae: 230.8374 - val_loss: 343536928.0000 - val_mae: 13094.1621\n",
      "Epoch 62/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 172927.2656 - mae: 234.6927 - val_loss: 343416864.0000 - val_mae: 13083.6064\n",
      "Epoch 63/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 168554.3281 - mae: 233.2458 - val_loss: 343516992.0000 - val_mae: 13083.6006\n",
      "Epoch 64/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 165723.5938 - mae: 230.6763 - val_loss: 343377376.0000 - val_mae: 13066.6445\n",
      "Epoch 65/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 169237.4688 - mae: 232.4489 - val_loss: 343733504.0000 - val_mae: 13075.0557\n",
      "Epoch 66/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 165655.1562 - mae: 231.4490 - val_loss: 343478816.0000 - val_mae: 13109.0420\n",
      "Epoch 67/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 170176.7344 - mae: 233.5526 - val_loss: 343434336.0000 - val_mae: 13079.9248\n",
      "Epoch 68/1000\n",
      "220/329 [===================>..........] - ETA: 0s - loss: 154078.3125 - mae: 221.9362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23060/115470395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train_scaled, y_reduced_train[28],\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_reduced_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           epochs=1000)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1092\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_reduced_train[28],\n",
    "          validation_data=(X_test_scaled, y_reduced_test[28]), \n",
    "          batch_size=16,\n",
    "          epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "95d482ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "reg_l1_l2 = regularizers.l1_l2(l1=0.005, l2=0.0005)\n",
    "\n",
    "def init_vanilla_nn_w_reg(n_neurons, input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(n_neurons[0], activation='relu', input_dim=input_dim))\n",
    "    model.add(layers.Dense(n_neurons[1], activation='relu', kernel_regularizer=reg_l1_l2))\n",
    "    for i in range(2, len(n_neurons)):\n",
    "        model.add(layers.Dense(n_neurons[i], activation='relu'))\n",
    "    model.add(layers.Dense(output_dim, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec7952c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(init_vanilla_nn_w_reg, n_neurons=nn, input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab649cc6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 90959120.0000 - mae: 4476.0298 - mse: 90959120.0000 - val_loss: 346538208.0000 - val_mae: 13807.5576 - val_mse: 346538208.0000\n",
      "Epoch 2/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 2441302.2500 - mae: 876.9330 - mse: 2441292.7500 - val_loss: 345351488.0000 - val_mae: 13579.3652 - val_mse: 345351488.0000\n",
      "Epoch 3/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 1662755.3750 - mae: 722.6714 - mse: 1662745.8750 - val_loss: 344935552.0000 - val_mae: 13498.1631 - val_mse: 344935552.0000\n",
      "Epoch 4/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1317022.6250 - mae: 644.5860 - mse: 1317013.3750 - val_loss: 344537856.0000 - val_mae: 13411.1104 - val_mse: 344537856.0000\n",
      "Epoch 5/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1072220.3750 - mae: 585.2071 - mse: 1072210.1250 - val_loss: 344375136.0000 - val_mae: 13363.3682 - val_mse: 344375136.0000\n",
      "Epoch 6/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 905395.4375 - mae: 537.6143 - mse: 905385.8125 - val_loss: 344562848.0000 - val_mae: 13402.9463 - val_mse: 344562848.0000\n",
      "Epoch 7/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 775260.4375 - mae: 497.3866 - mse: 775250.5000 - val_loss: 344190688.0000 - val_mae: 13287.6543 - val_mse: 344190688.0000\n",
      "Epoch 8/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 664992.6875 - mae: 462.1623 - mse: 664983.5000 - val_loss: 343842080.0000 - val_mae: 13264.4590 - val_mse: 343842080.0000\n",
      "Epoch 9/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 598915.1250 - mae: 439.6404 - mse: 598905.6250 - val_loss: 343886752.0000 - val_mae: 13245.2295 - val_mse: 343886752.0000\n",
      "Epoch 10/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 552141.3125 - mae: 421.5251 - mse: 552131.5625 - val_loss: 344012672.0000 - val_mae: 13254.2539 - val_mse: 344012672.0000\n",
      "Epoch 11/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 512534.1875 - mae: 406.8595 - mse: 512524.5938 - val_loss: 343803136.0000 - val_mae: 13205.6289 - val_mse: 343803136.0000\n",
      "Epoch 12/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 441690.6875 - mae: 376.5309 - mse: 441681.0312 - val_loss: 343806848.0000 - val_mae: 13178.5684 - val_mse: 343806848.0000\n",
      "Epoch 13/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 432518.9375 - mae: 373.2311 - mse: 432509.4062 - val_loss: 343647360.0000 - val_mae: 13178.2627 - val_mse: 343647360.0000\n",
      "Epoch 14/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 407296.9062 - mae: 360.4901 - mse: 407287.0312 - val_loss: 343598592.0000 - val_mae: 13153.1875 - val_mse: 343598592.0000\n",
      "Epoch 15/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 369379.0000 - mae: 342.4400 - mse: 369369.4062 - val_loss: 343706240.0000 - val_mae: 13180.9609 - val_mse: 343706240.0000\n",
      "Epoch 16/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 349768.5000 - mae: 337.4354 - mse: 349758.9062 - val_loss: 343685248.0000 - val_mae: 13148.0996 - val_mse: 343685248.0000\n",
      "Epoch 17/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 341296.4688 - mae: 332.1769 - mse: 341286.8750 - val_loss: 343560096.0000 - val_mae: 13136.7930 - val_mse: 343560096.0000\n",
      "Epoch 18/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 315988.7500 - mae: 319.3592 - mse: 315979.3125 - val_loss: 343623904.0000 - val_mae: 13120.5957 - val_mse: 343623904.0000\n",
      "Epoch 19/1000\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 314329.0000 - mae: 318.0163 - mse: 314319.5938 - val_loss: 343623904.0000 - val_mae: 13135.0889 - val_mse: 343623904.0000\n",
      "Epoch 20/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 311626.6562 - mae: 318.0262 - mse: 311617.1562 - val_loss: 343613344.0000 - val_mae: 13120.6484 - val_mse: 343613344.0000\n",
      "Epoch 21/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 293854.3750 - mae: 308.4157 - mse: 293845.1250 - val_loss: 343549152.0000 - val_mae: 13165.9150 - val_mse: 343549152.0000\n",
      "Epoch 22/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 306956.6875 - mae: 315.9083 - mse: 306947.1562 - val_loss: 343456608.0000 - val_mae: 13100.6924 - val_mse: 343456608.0000\n",
      "Epoch 23/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 278311.0312 - mae: 299.2816 - mse: 278301.6562 - val_loss: 343428448.0000 - val_mae: 13110.7334 - val_mse: 343428448.0000\n",
      "Epoch 24/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 287649.1562 - mae: 302.5643 - mse: 287639.6250 - val_loss: 343915232.0000 - val_mae: 13254.2500 - val_mse: 343915232.0000\n",
      "Epoch 25/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 278443.7188 - mae: 297.6424 - mse: 278434.2812 - val_loss: 343678336.0000 - val_mae: 13156.3828 - val_mse: 343678336.0000\n",
      "Epoch 26/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 268733.9375 - mae: 293.8899 - mse: 268724.5625 - val_loss: 343502784.0000 - val_mae: 13099.7178 - val_mse: 343502784.0000\n",
      "Epoch 27/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 263319.8750 - mae: 291.3848 - mse: 263310.3125 - val_loss: 343375264.0000 - val_mae: 13125.8584 - val_mse: 343375264.0000\n",
      "Epoch 28/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 246147.0000 - mae: 280.0278 - mse: 246137.5625 - val_loss: 343502496.0000 - val_mae: 13108.6455 - val_mse: 343502496.0000\n",
      "Epoch 29/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 259385.1562 - mae: 288.5019 - mse: 259375.7344 - val_loss: 343452576.0000 - val_mae: 13110.6719 - val_mse: 343452576.0000\n",
      "Epoch 30/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 239851.5469 - mae: 277.8347 - mse: 239842.2031 - val_loss: 343595360.0000 - val_mae: 13116.6885 - val_mse: 343595360.0000\n",
      "Epoch 31/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 242618.9062 - mae: 279.6686 - mse: 242609.5625 - val_loss: 343500288.0000 - val_mae: 13117.9473 - val_mse: 343500288.0000\n",
      "Epoch 32/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 241819.6406 - mae: 277.2879 - mse: 241810.1875 - val_loss: 343738336.0000 - val_mae: 13115.9121 - val_mse: 343738336.0000\n",
      "Epoch 33/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 239501.0625 - mae: 276.9615 - mse: 239491.5156 - val_loss: 343618816.0000 - val_mae: 13093.2939 - val_mse: 343618816.0000\n",
      "Epoch 34/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 238981.1250 - mae: 277.3522 - mse: 238971.8125 - val_loss: 343406976.0000 - val_mae: 13095.2070 - val_mse: 343406976.0000\n",
      "Epoch 35/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 215329.7969 - mae: 263.7822 - mse: 215320.2812 - val_loss: 343518688.0000 - val_mae: 13101.1250 - val_mse: 343518688.0000\n",
      "Epoch 36/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 232905.2969 - mae: 273.0150 - mse: 232896.0000 - val_loss: 343506816.0000 - val_mae: 13108.1631 - val_mse: 343506816.0000\n",
      "Epoch 37/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 218081.7500 - mae: 263.5077 - mse: 218072.2031 - val_loss: 343556128.0000 - val_mae: 13092.0146 - val_mse: 343556128.0000\n",
      "Epoch 38/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 220050.7188 - mae: 265.3215 - mse: 220041.1719 - val_loss: 343420032.0000 - val_mae: 13083.4189 - val_mse: 343420032.0000\n",
      "Epoch 39/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 207816.1250 - mae: 258.0778 - mse: 207806.5156 - val_loss: 343443264.0000 - val_mae: 13073.7969 - val_mse: 343443264.0000\n",
      "Epoch 40/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 226907.2031 - mae: 270.2097 - mse: 226897.6250 - val_loss: 343501920.0000 - val_mae: 13101.6973 - val_mse: 343501920.0000\n",
      "Epoch 41/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 216983.2031 - mae: 263.2365 - mse: 216973.6562 - val_loss: 343658624.0000 - val_mae: 13101.0898 - val_mse: 343658624.0000\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 1s 2ms/step - loss: 211484.7656 - mae: 260.4957 - mse: 211475.1875 - val_loss: 343433728.0000 - val_mae: 13105.7168 - val_mse: 343433728.0000\n",
      "Epoch 43/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 200990.9219 - mae: 253.8279 - mse: 200981.5469 - val_loss: 343384352.0000 - val_mae: 13071.5420 - val_mse: 343384352.0000\n",
      "Epoch 44/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 202420.5469 - mae: 256.5647 - mse: 202410.9531 - val_loss: 343506816.0000 - val_mae: 13093.5068 - val_mse: 343506816.0000\n",
      "Epoch 45/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 213205.6719 - mae: 262.7970 - mse: 213196.0938 - val_loss: 343484640.0000 - val_mae: 13111.1055 - val_mse: 343484640.0000\n",
      "Epoch 46/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 206890.2031 - mae: 257.6681 - mse: 206880.7656 - val_loss: 343569856.0000 - val_mae: 13138.2393 - val_mse: 343569856.0000\n",
      "Epoch 47/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 207477.0469 - mae: 258.8444 - mse: 207467.6875 - val_loss: 343477920.0000 - val_mae: 13098.1807 - val_mse: 343477920.0000\n",
      "Epoch 48/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 198711.7969 - mae: 251.8598 - mse: 198702.2812 - val_loss: 343473696.0000 - val_mae: 13075.6924 - val_mse: 343473696.0000\n",
      "Epoch 49/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 198380.0625 - mae: 252.9661 - mse: 198370.6406 - val_loss: 343332416.0000 - val_mae: 13091.2949 - val_mse: 343332416.0000\n",
      "Epoch 50/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 199558.4688 - mae: 253.4071 - mse: 199548.9219 - val_loss: 343581728.0000 - val_mae: 13106.1748 - val_mse: 343581728.0000\n",
      "Epoch 51/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 200429.0781 - mae: 254.1358 - mse: 200419.5781 - val_loss: 343728704.0000 - val_mae: 13175.0859 - val_mse: 343728704.0000\n",
      "Epoch 52/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 191979.0625 - mae: 249.4729 - mse: 191969.5469 - val_loss: 343546112.0000 - val_mae: 13088.8057 - val_mse: 343546112.0000\n",
      "Epoch 53/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 190273.7344 - mae: 246.7194 - mse: 190264.1094 - val_loss: 343500544.0000 - val_mae: 13072.1299 - val_mse: 343500544.0000\n",
      "Epoch 54/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 180292.1094 - mae: 240.5802 - mse: 180282.7031 - val_loss: 343669056.0000 - val_mae: 13140.1924 - val_mse: 343669056.0000\n",
      "Epoch 55/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 206375.8438 - mae: 256.8491 - mse: 206366.3750 - val_loss: 343568416.0000 - val_mae: 13107.5859 - val_mse: 343568416.0000\n",
      "Epoch 56/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 189393.7969 - mae: 245.6160 - mse: 189384.3438 - val_loss: 343517888.0000 - val_mae: 13068.5830 - val_mse: 343517888.0000\n",
      "Epoch 57/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 180147.7344 - mae: 241.3795 - mse: 180138.2969 - val_loss: 343442080.0000 - val_mae: 13078.9531 - val_mse: 343442080.0000\n",
      "Epoch 58/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 190718.4219 - mae: 246.5101 - mse: 190708.8594 - val_loss: 343415552.0000 - val_mae: 13079.7939 - val_mse: 343415552.0000\n",
      "Epoch 59/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 185760.2500 - mae: 243.9160 - mse: 185750.6562 - val_loss: 343364288.0000 - val_mae: 13085.8975 - val_mse: 343364288.0000\n",
      "Epoch 60/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 188686.5938 - mae: 246.5488 - mse: 188677.2188 - val_loss: 343547392.0000 - val_mae: 13077.6260 - val_mse: 343547392.0000\n",
      "Epoch 61/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 175645.3594 - mae: 236.0937 - mse: 175635.7500 - val_loss: 343553504.0000 - val_mae: 13076.0225 - val_mse: 343553504.0000\n",
      "Epoch 62/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 173926.2812 - mae: 236.3030 - mse: 173916.7500 - val_loss: 343669024.0000 - val_mae: 13080.4180 - val_mse: 343669024.0000\n",
      "Epoch 63/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 187811.0156 - mae: 245.7205 - mse: 187801.4844 - val_loss: 343583040.0000 - val_mae: 13100.6748 - val_mse: 343583040.0000\n",
      "Epoch 64/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 172595.4844 - mae: 235.2347 - mse: 172585.9688 - val_loss: 343479968.0000 - val_mae: 13083.9717 - val_mse: 343479968.0000\n",
      "Epoch 65/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 172593.7031 - mae: 234.7064 - mse: 172584.0625 - val_loss: 343618720.0000 - val_mae: 13073.4629 - val_mse: 343618720.0000\n",
      "Epoch 66/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 175052.5625 - mae: 237.2301 - mse: 175042.9688 - val_loss: 343466560.0000 - val_mae: 13079.6133 - val_mse: 343466560.0000\n",
      "Epoch 67/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 170769.7188 - mae: 233.8519 - mse: 170760.0625 - val_loss: 343527200.0000 - val_mae: 13094.8154 - val_mse: 343527200.0000\n",
      "Epoch 68/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 169611.4062 - mae: 233.9798 - mse: 169601.7031 - val_loss: 343615904.0000 - val_mae: 13076.7568 - val_mse: 343615904.0000\n",
      "Epoch 69/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 169446.1250 - mae: 232.5116 - mse: 169436.5156 - val_loss: 343532160.0000 - val_mae: 13073.5127 - val_mse: 343532160.0000\n",
      "Epoch 70/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 171064.9219 - mae: 233.4341 - mse: 171055.3281 - val_loss: 343474368.0000 - val_mae: 13074.1260 - val_mse: 343474368.0000\n",
      "Epoch 71/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 176799.9062 - mae: 237.6924 - mse: 176790.2812 - val_loss: 343474368.0000 - val_mae: 13085.6582 - val_mse: 343474368.0000\n",
      "Epoch 72/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 162086.3438 - mae: 227.6412 - mse: 162076.6406 - val_loss: 343538432.0000 - val_mae: 13075.1543 - val_mse: 343538432.0000\n",
      "Epoch 73/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 169612.9688 - mae: 231.2356 - mse: 169603.4062 - val_loss: 343459744.0000 - val_mae: 13092.3945 - val_mse: 343459744.0000\n",
      "Epoch 74/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 165475.1875 - mae: 229.3045 - mse: 165465.6094 - val_loss: 343535392.0000 - val_mae: 13111.0576 - val_mse: 343535392.0000\n",
      "Epoch 75/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 161834.7344 - mae: 228.0656 - mse: 161825.0469 - val_loss: 343441568.0000 - val_mae: 13114.6270 - val_mse: 343441568.0000\n",
      "Epoch 76/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 163130.7812 - mae: 229.2944 - mse: 163121.0469 - val_loss: 343509376.0000 - val_mae: 13137.9072 - val_mse: 343509376.0000\n",
      "Epoch 77/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 156204.9375 - mae: 222.6464 - mse: 156195.2500 - val_loss: 343458112.0000 - val_mae: 13080.5264 - val_mse: 343458112.0000\n",
      "Epoch 78/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 154828.2188 - mae: 221.9389 - mse: 154818.5781 - val_loss: 343396992.0000 - val_mae: 13072.9502 - val_mse: 343396992.0000\n",
      "Epoch 79/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 167486.3906 - mae: 231.4215 - mse: 167476.6719 - val_loss: 343589856.0000 - val_mae: 13097.0205 - val_mse: 343589856.0000\n",
      "Epoch 80/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 175944.6719 - mae: 237.8776 - mse: 175935.0625 - val_loss: 343356480.0000 - val_mae: 13078.9258 - val_mse: 343356480.0000\n",
      "Epoch 81/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 150863.4844 - mae: 220.5627 - mse: 150853.7500 - val_loss: 343470592.0000 - val_mae: 13075.0840 - val_mse: 343470592.0000\n",
      "Epoch 82/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 144702.8438 - mae: 215.6986 - mse: 144693.0781 - val_loss: 343579040.0000 - val_mae: 13101.3838 - val_mse: 343579040.0000\n",
      "Epoch 83/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 1s 2ms/step - loss: 158034.4688 - mae: 224.5312 - mse: 158024.7344 - val_loss: 343491936.0000 - val_mae: 13066.2559 - val_mse: 343491936.0000\n",
      "Epoch 84/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 155166.5781 - mae: 222.0206 - mse: 155156.8438 - val_loss: 343405248.0000 - val_mae: 13064.1572 - val_mse: 343405248.0000\n",
      "Epoch 85/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 153318.2344 - mae: 221.2574 - mse: 153308.5156 - val_loss: 343399168.0000 - val_mae: 13073.8799 - val_mse: 343399168.0000\n",
      "Epoch 86/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 147088.5000 - mae: 217.4721 - mse: 147078.6875 - val_loss: 343458208.0000 - val_mae: 13076.5264 - val_mse: 343458208.0000\n",
      "Epoch 87/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 151426.8750 - mae: 219.6242 - mse: 151417.1562 - val_loss: 343435840.0000 - val_mae: 13064.3691 - val_mse: 343435840.0000\n",
      "Epoch 88/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 153535.3125 - mae: 222.7335 - mse: 153525.6250 - val_loss: 343394272.0000 - val_mae: 13072.5381 - val_mse: 343394272.0000\n",
      "Epoch 89/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 150261.3750 - mae: 218.6046 - mse: 150251.6250 - val_loss: 343532416.0000 - val_mae: 13113.1836 - val_mse: 343532416.0000\n",
      "Epoch 90/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 152848.0000 - mae: 221.1168 - mse: 152838.1406 - val_loss: 343493216.0000 - val_mae: 13072.5303 - val_mse: 343493216.0000\n",
      "Epoch 91/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 158758.1250 - mae: 224.7498 - mse: 158748.2969 - val_loss: 343472416.0000 - val_mae: 13099.1758 - val_mse: 343472416.0000\n",
      "Epoch 92/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 141998.8750 - mae: 213.3754 - mse: 141989.1094 - val_loss: 343585632.0000 - val_mae: 13071.5000 - val_mse: 343585632.0000\n",
      "Epoch 93/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 144913.6250 - mae: 214.2144 - mse: 144903.8438 - val_loss: 343541376.0000 - val_mae: 13068.7627 - val_mse: 343541376.0000\n",
      "Epoch 94/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 149160.6875 - mae: 219.5428 - mse: 149150.8281 - val_loss: 343568736.0000 - val_mae: 13081.3779 - val_mse: 343568736.0000\n",
      "Epoch 95/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 142088.9844 - mae: 212.4870 - mse: 142079.0781 - val_loss: 343593952.0000 - val_mae: 13073.2227 - val_mse: 343593952.0000\n",
      "Epoch 96/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 150538.2188 - mae: 218.5918 - mse: 150528.4375 - val_loss: 343434112.0000 - val_mae: 13066.3711 - val_mse: 343434112.0000\n",
      "Epoch 97/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 138379.0156 - mae: 210.3193 - mse: 138369.1719 - val_loss: 343752288.0000 - val_mae: 13107.1553 - val_mse: 343752288.0000\n",
      "Epoch 98/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 140526.3906 - mae: 212.0206 - mse: 140516.4375 - val_loss: 343388256.0000 - val_mae: 13075.1436 - val_mse: 343388256.0000\n",
      "Epoch 99/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 136186.8125 - mae: 209.0495 - mse: 136176.9688 - val_loss: 343378944.0000 - val_mae: 13072.6387 - val_mse: 343378944.0000\n",
      "Epoch 100/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 139101.5625 - mae: 210.0150 - mse: 139091.6875 - val_loss: 343478240.0000 - val_mae: 13084.1758 - val_mse: 343478240.0000\n",
      "Epoch 101/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 144507.7031 - mae: 216.3275 - mse: 144497.9062 - val_loss: 343565824.0000 - val_mae: 13124.0479 - val_mse: 343565824.0000\n",
      "Epoch 102/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 155790.2812 - mae: 222.9325 - mse: 155780.4062 - val_loss: 343714432.0000 - val_mae: 13195.0811 - val_mse: 343714432.0000\n",
      "Epoch 103/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 135155.9375 - mae: 207.0488 - mse: 135145.9688 - val_loss: 343578144.0000 - val_mae: 13089.3838 - val_mse: 343578144.0000\n",
      "Epoch 104/1000\n",
      "215/329 [==================>...........] - ETA: 0s - loss: 144135.2344 - mae: 215.8952 - mse: 144125.2969"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23060/115470395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train_scaled, y_reduced_train[28],\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_reduced_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           epochs=1000)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1092\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_reduced_train[28],\n",
    "          validation_data=(X_test_scaled, y_reduced_test[28]), \n",
    "          batch_size=16,\n",
    "          epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7772dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos una red más simple\n",
    "\n",
    "nn = (60, 25, 25, 10) #Anterior (150, 100, 50, 50, 25, 10)\n",
    "\n",
    "model = KerasRegressor(init_vanilla_nn, n_neurons=nn, input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "70436389",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 247990176.0000 - mae: 10355.7773 - val_loss: 379875040.0000 - val_mae: 16530.5176\n",
      "Epoch 2/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 17389138.0000 - mae: 2513.7275 - val_loss: 351604768.0000 - val_mae: 14524.2139\n",
      "Epoch 3/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 5229878.0000 - mae: 1354.8046 - val_loss: 346843360.0000 - val_mae: 13885.7480\n",
      "Epoch 4/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 2669767.7500 - mae: 939.0933 - val_loss: 345364768.0000 - val_mae: 13624.1523\n",
      "Epoch 5/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1856584.7500 - mae: 768.1232 - val_loss: 344848768.0000 - val_mae: 13507.4307\n",
      "Epoch 6/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1483974.1250 - mae: 681.9594 - val_loss: 344752864.0000 - val_mae: 13448.1631\n",
      "Epoch 7/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1252126.7500 - mae: 626.1968 - val_loss: 344460672.0000 - val_mae: 13386.1240\n",
      "Epoch 8/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 1083614.5000 - mae: 584.1877 - val_loss: 344212800.0000 - val_mae: 13350.8584\n",
      "Epoch 9/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 958841.0000 - mae: 549.5327 - val_loss: 344165696.0000 - val_mae: 13325.8350\n",
      "Epoch 10/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 853109.9375 - mae: 518.1508 - val_loss: 344046080.0000 - val_mae: 13292.6553\n",
      "Epoch 11/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 765288.1250 - mae: 490.9915 - val_loss: 344077408.0000 - val_mae: 13277.6094\n",
      "Epoch 12/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 701442.4375 - mae: 472.1948 - val_loss: 343979168.0000 - val_mae: 13252.3057\n",
      "Epoch 13/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 644234.3125 - mae: 452.6896 - val_loss: 343927680.0000 - val_mae: 13236.8115\n",
      "Epoch 14/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 593720.0000 - mae: 434.7960 - val_loss: 343931008.0000 - val_mae: 13226.3379\n",
      "Epoch 15/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 559839.3125 - mae: 423.7386 - val_loss: 343785952.0000 - val_mae: 13206.4814\n",
      "Epoch 16/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 519377.5312 - mae: 406.2506 - val_loss: 343869248.0000 - val_mae: 13201.0000\n",
      "Epoch 17/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 490822.6562 - mae: 396.9296 - val_loss: 343716416.0000 - val_mae: 13195.0986\n",
      "Epoch 18/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 463484.2812 - mae: 385.8572 - val_loss: 343741088.0000 - val_mae: 13181.3730\n",
      "Epoch 19/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 443988.1250 - mae: 377.7875 - val_loss: 343589888.0000 - val_mae: 13168.3799\n",
      "Epoch 20/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 423144.5938 - mae: 370.7051 - val_loss: 343675072.0000 - val_mae: 13162.6113\n",
      "Epoch 21/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 404820.8438 - mae: 361.0374 - val_loss: 343754880.0000 - val_mae: 13164.8818\n",
      "Epoch 22/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 390881.4375 - mae: 355.1975 - val_loss: 343563072.0000 - val_mae: 13145.5752\n",
      "Epoch 23/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 373429.0312 - mae: 347.2847 - val_loss: 343686656.0000 - val_mae: 13142.3086\n",
      "Epoch 24/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 359739.5000 - mae: 341.4589 - val_loss: 343643968.0000 - val_mae: 13143.0176\n",
      "Epoch 25/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 353374.0312 - mae: 336.3077 - val_loss: 343599648.0000 - val_mae: 13131.9805\n",
      "Epoch 26/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 338335.8750 - mae: 329.6804 - val_loss: 343532224.0000 - val_mae: 13140.1084\n",
      "Epoch 27/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 325951.6250 - mae: 323.6737 - val_loss: 343620320.0000 - val_mae: 13123.8525\n",
      "Epoch 28/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 317894.3750 - mae: 320.6915 - val_loss: 343409088.0000 - val_mae: 13122.4512\n",
      "Epoch 29/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 306748.1250 - mae: 313.9606 - val_loss: 343551936.0000 - val_mae: 13122.5889\n",
      "Epoch 30/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 299496.1250 - mae: 310.5479 - val_loss: 343588128.0000 - val_mae: 13119.8662\n",
      "Epoch 31/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 295114.6875 - mae: 309.1631 - val_loss: 343506144.0000 - val_mae: 13115.5312\n",
      "Epoch 32/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 289987.2500 - mae: 306.3955 - val_loss: 343535648.0000 - val_mae: 13106.6602\n",
      "Epoch 33/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 282449.9062 - mae: 302.0941 - val_loss: 343549568.0000 - val_mae: 13104.2930\n",
      "Epoch 34/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 275299.1875 - mae: 300.0587 - val_loss: 343503072.0000 - val_mae: 13103.2988\n",
      "Epoch 35/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 271923.4688 - mae: 296.4623 - val_loss: 343505920.0000 - val_mae: 13100.7822\n",
      "Epoch 36/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 268065.7188 - mae: 295.8379 - val_loss: 343565952.0000 - val_mae: 13104.1035\n",
      "Epoch 37/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 265454.8750 - mae: 293.9203 - val_loss: 343577696.0000 - val_mae: 13092.3398\n",
      "Epoch 38/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 258135.8750 - mae: 289.3714 - val_loss: 343521760.0000 - val_mae: 13092.9902\n",
      "Epoch 39/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 253631.6406 - mae: 286.4038 - val_loss: 343492032.0000 - val_mae: 13090.3477\n",
      "Epoch 40/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 256040.6406 - mae: 287.6504 - val_loss: 343574144.0000 - val_mae: 13087.0840\n",
      "Epoch 41/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 249721.3750 - mae: 284.8784 - val_loss: 343578624.0000 - val_mae: 13112.7598\n",
      "Epoch 42/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 245969.4531 - mae: 282.6978 - val_loss: 343491008.0000 - val_mae: 13090.2051\n",
      "Epoch 43/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 245212.2344 - mae: 282.0833 - val_loss: 343488288.0000 - val_mae: 13085.6904\n",
      "Epoch 44/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 238677.0938 - mae: 278.2605 - val_loss: 343446848.0000 - val_mae: 13083.0186\n",
      "Epoch 45/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 236041.6250 - mae: 276.3757 - val_loss: 343468704.0000 - val_mae: 13082.3008\n",
      "Epoch 46/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 236858.9844 - mae: 277.5409 - val_loss: 343416928.0000 - val_mae: 13085.8271\n",
      "Epoch 47/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 236090.7812 - mae: 276.4150 - val_loss: 343616800.0000 - val_mae: 13095.8574\n",
      "Epoch 48/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 229511.7500 - mae: 273.0325 - val_loss: 343446560.0000 - val_mae: 13078.7256\n",
      "Epoch 49/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 226923.2812 - mae: 271.3000 - val_loss: 343518432.0000 - val_mae: 13078.4678\n",
      "Epoch 50/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 231018.7812 - mae: 275.5721 - val_loss: 343569696.0000 - val_mae: 13082.8223\n",
      "Epoch 51/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 225533.8281 - mae: 270.5698 - val_loss: 343561792.0000 - val_mae: 13082.9971\n",
      "Epoch 52/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 222239.8594 - mae: 269.3362 - val_loss: 343452224.0000 - val_mae: 13074.2090\n",
      "Epoch 53/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 224560.7812 - mae: 270.0589 - val_loss: 343542720.0000 - val_mae: 13086.6602\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 1s 2ms/step - loss: 219329.2969 - mae: 267.0456 - val_loss: 343385408.0000 - val_mae: 13068.6104\n",
      "Epoch 55/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 214636.2969 - mae: 263.3524 - val_loss: 343451808.0000 - val_mae: 13067.6611\n",
      "Epoch 56/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 218146.0781 - mae: 266.5094 - val_loss: 343397952.0000 - val_mae: 13071.8350\n",
      "Epoch 57/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 213520.0469 - mae: 262.8047 - val_loss: 343448480.0000 - val_mae: 13068.3955\n",
      "Epoch 58/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 211851.7969 - mae: 262.0847 - val_loss: 343577824.0000 - val_mae: 13083.8457\n",
      "Epoch 59/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 217800.2344 - mae: 264.2344 - val_loss: 343538080.0000 - val_mae: 13076.6045\n",
      "Epoch 60/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 207576.6719 - mae: 259.7446 - val_loss: 343463456.0000 - val_mae: 13070.8789\n",
      "Epoch 61/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 211268.1406 - mae: 261.9680 - val_loss: 343570016.0000 - val_mae: 13077.6426\n",
      "Epoch 62/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 211956.0000 - mae: 262.9253 - val_loss: 343409728.0000 - val_mae: 13069.7744\n",
      "Epoch 63/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 204421.3125 - mae: 257.6343 - val_loss: 343576864.0000 - val_mae: 13074.5771\n",
      "Epoch 64/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 211042.5938 - mae: 261.4617 - val_loss: 343433248.0000 - val_mae: 13066.0156\n",
      "Epoch 65/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 207402.5469 - mae: 260.5224 - val_loss: 343414752.0000 - val_mae: 13060.9980\n",
      "Epoch 66/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 202926.8281 - mae: 257.9530 - val_loss: 343469536.0000 - val_mae: 13071.1289\n",
      "Epoch 67/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 205095.2344 - mae: 257.1896 - val_loss: 343395328.0000 - val_mae: 13084.9834\n",
      "Epoch 68/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 204343.3906 - mae: 257.4914 - val_loss: 343426368.0000 - val_mae: 13071.0840\n",
      "Epoch 69/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 199361.0625 - mae: 255.1521 - val_loss: 343404320.0000 - val_mae: 13061.5195\n",
      "Epoch 70/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 199653.2031 - mae: 254.0607 - val_loss: 343590944.0000 - val_mae: 13067.2725\n",
      "Epoch 71/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 201006.2031 - mae: 255.3559 - val_loss: 343529184.0000 - val_mae: 13066.0068\n",
      "Epoch 72/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 198470.7656 - mae: 255.0337 - val_loss: 343397696.0000 - val_mae: 13064.5166\n",
      "Epoch 73/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 194632.4062 - mae: 251.6639 - val_loss: 343515744.0000 - val_mae: 13061.6260\n",
      "Epoch 74/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 195005.8281 - mae: 253.0067 - val_loss: 343365952.0000 - val_mae: 13061.7354\n",
      "Epoch 75/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 198982.1250 - mae: 253.2236 - val_loss: 343447200.0000 - val_mae: 13079.3623\n",
      "Epoch 76/1000\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 194801.5625 - mae: 252.2515 - val_loss: 343456000.0000 - val_mae: 13062.8379\n",
      "Epoch 77/1000\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 192140.6250 - mae: 250.0531 - val_loss: 343470464.0000 - val_mae: 13060.6182\n",
      "Epoch 78/1000\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 194441.8438 - mae: 251.5743 - val_loss: 343327936.0000 - val_mae: 13057.3896\n",
      "Epoch 79/1000\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 192114.8125 - mae: 250.4743 - val_loss: 343476672.0000 - val_mae: 13057.2402\n",
      "Epoch 80/1000\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 191591.1250 - mae: 251.1434 - val_loss: 343385760.0000 - val_mae: 13058.4814\n",
      "Epoch 81/1000\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 190182.7969 - mae: 248.5040 - val_loss: 343683744.0000 - val_mae: 13066.0273\n",
      "Epoch 82/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 193235.2188 - mae: 250.9249 - val_loss: 343464128.0000 - val_mae: 13064.5000\n",
      "Epoch 83/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 189550.4531 - mae: 248.9058 - val_loss: 343417312.0000 - val_mae: 13064.7529\n",
      "Epoch 84/1000\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 189771.9062 - mae: 250.1179 - val_loss: 343384320.0000 - val_mae: 13062.4307\n",
      "Epoch 85/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 187493.1250 - mae: 246.7986 - val_loss: 343510688.0000 - val_mae: 13065.0410\n",
      "Epoch 86/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 187165.9375 - mae: 246.9193 - val_loss: 343448064.0000 - val_mae: 13063.1855\n",
      "Epoch 87/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 186424.7812 - mae: 246.8624 - val_loss: 343471392.0000 - val_mae: 13067.1416\n",
      "Epoch 88/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 186992.5156 - mae: 247.1197 - val_loss: 343543776.0000 - val_mae: 13062.2725\n",
      "Epoch 89/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 189804.8906 - mae: 247.8641 - val_loss: 343392640.0000 - val_mae: 13063.0303\n",
      "Epoch 90/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 187242.7344 - mae: 247.1997 - val_loss: 343638304.0000 - val_mae: 13064.4014\n",
      "Epoch 91/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 186508.0938 - mae: 246.5456 - val_loss: 343405056.0000 - val_mae: 13054.8271\n",
      "Epoch 92/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 181458.8281 - mae: 243.3473 - val_loss: 343429312.0000 - val_mae: 13055.8359\n",
      "Epoch 93/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 182886.1250 - mae: 244.5769 - val_loss: 343416768.0000 - val_mae: 13058.7686\n",
      "Epoch 94/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 184974.2188 - mae: 244.9768 - val_loss: 343423200.0000 - val_mae: 13052.7998\n",
      "Epoch 95/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 183366.1875 - mae: 244.3769 - val_loss: 343324608.0000 - val_mae: 13061.6064\n",
      "Epoch 96/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 187318.0938 - mae: 246.9311 - val_loss: 343486496.0000 - val_mae: 13058.8623\n",
      "Epoch 97/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 184809.4375 - mae: 245.0470 - val_loss: 343378624.0000 - val_mae: 13054.1240\n",
      "Epoch 98/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 178583.7031 - mae: 241.5573 - val_loss: 343462912.0000 - val_mae: 13057.1299\n",
      "Epoch 99/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 183616.5156 - mae: 245.3190 - val_loss: 343614144.0000 - val_mae: 13069.8369\n",
      "Epoch 100/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 180943.7812 - mae: 243.1656 - val_loss: 343449984.0000 - val_mae: 13056.4639\n",
      "Epoch 101/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 177788.9219 - mae: 240.3532 - val_loss: 343451616.0000 - val_mae: 13057.5605\n",
      "Epoch 102/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 184243.8750 - mae: 245.3593 - val_loss: 343337120.0000 - val_mae: 13054.9004\n",
      "Epoch 103/1000\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 177972.5469 - mae: 241.8383 - val_loss: 343300576.0000 - val_mae: 13074.5332\n",
      "Epoch 104/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 182679.4375 - mae: 243.7395 - val_loss: 343369408.0000 - val_mae: 13051.7715\n",
      "Epoch 105/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 178820.2969 - mae: 241.2335 - val_loss: 343475520.0000 - val_mae: 13057.6719\n",
      "Epoch 106/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 176329.6406 - mae: 239.1451 - val_loss: 343360672.0000 - val_mae: 13052.6484\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 1s 2ms/step - loss: 180775.5469 - mae: 241.9735 - val_loss: 343403008.0000 - val_mae: 13057.4277\n",
      "Epoch 108/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 174873.2656 - mae: 239.6587 - val_loss: 343513216.0000 - val_mae: 13054.9541\n",
      "Epoch 109/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 177906.5000 - mae: 239.9822 - val_loss: 343470144.0000 - val_mae: 13075.3135\n",
      "Epoch 110/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 177237.1250 - mae: 240.8434 - val_loss: 343366688.0000 - val_mae: 13064.2256\n",
      "Epoch 111/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 175328.9062 - mae: 239.4029 - val_loss: 343471520.0000 - val_mae: 13053.9111\n",
      "Epoch 112/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 178324.0156 - mae: 241.1885 - val_loss: 343384800.0000 - val_mae: 13051.7178\n",
      "Epoch 113/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 174213.0156 - mae: 237.8025 - val_loss: 343505120.0000 - val_mae: 13060.5654\n",
      "Epoch 114/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 173589.4844 - mae: 238.1214 - val_loss: 343464000.0000 - val_mae: 13056.7402\n",
      "Epoch 115/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 173524.4375 - mae: 237.1173 - val_loss: 343547392.0000 - val_mae: 13057.4717\n",
      "Epoch 116/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 175403.9844 - mae: 239.1242 - val_loss: 343352352.0000 - val_mae: 13060.9805\n",
      "Epoch 117/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 175773.0312 - mae: 239.2247 - val_loss: 343481376.0000 - val_mae: 13052.5664\n",
      "Epoch 118/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 178210.2188 - mae: 241.3190 - val_loss: 343644480.0000 - val_mae: 13058.9775\n",
      "Epoch 119/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 174002.6250 - mae: 238.1386 - val_loss: 343397216.0000 - val_mae: 13051.8262\n",
      "Epoch 120/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 172234.5156 - mae: 237.1459 - val_loss: 343336064.0000 - val_mae: 13062.4092\n",
      "Epoch 121/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 171769.1406 - mae: 236.5814 - val_loss: 343402400.0000 - val_mae: 13051.8271\n",
      "Epoch 122/1000\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 169874.5000 - mae: 235.3588 - val_loss: 343445600.0000 - val_mae: 13054.7773\n",
      "Epoch 123/1000\n",
      "162/329 [=============>................] - ETA: 0s - loss: 168223.8281 - mae: 234.0450"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23060/115470395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train_scaled, y_reduced_train[28],\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_reduced_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           epochs=1000)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1092\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_reduced_train[28],\n",
    "          validation_data=(X_test_scaled, y_reduced_test[28]), \n",
    "          batch_size=16,\n",
    "          epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee84a83",
   "metadata": {},
   "source": [
    "### Escenario - Dataset con hora por fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a25d97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_h = pd.concat([X_per_h, y_per_h], axis = 1)\n",
    "data_per_h = data_per_h.head(100_000)\n",
    "\n",
    "X_per_h = data_per_h[X_per_h.columns]\n",
    "y_per_h = data_per_h[y_per_h.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bf330b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 7)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_per_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0261ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_per_h)\n",
    "columns = X_per_h.columns\n",
    "\n",
    "X_scaled = pd.DataFrame(scaler.transform(X_per_h), columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "33ea59cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0000\n",
       "1       1.6818\n",
       "2       1.6818\n",
       "3       1.6818\n",
       "4       1.6818\n",
       "        ...   \n",
       "539    74.1547\n",
       "540    75.8138\n",
       "541    81.2446\n",
       "542    83.6257\n",
       "543    89.8895\n",
       "Length: 100000, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_per_h_total = y_per_h.sum(axis=1)\n",
    "y_per_h_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9fc665e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled, y_per_h_total, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d87961b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_scaled_train.shape[1]\n",
    "output_dim = y_train.shape[0]\n",
    "nn = (50, 25, 10)\n",
    "\n",
    "model = KerasRegressor(init_vanilla_nn, n_neurons=nn, input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "69063457",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2188/2188 [==============================] - 72s 33ms/step - loss: 526.3610 - mae: 13.2892 - val_loss: 339.0059 - val_mae: 10.9425\n",
      "Epoch 2/100\n",
      "2188/2188 [==============================] - 73s 33ms/step - loss: 317.2792 - mae: 10.0326 - val_loss: 285.9495 - val_mae: 9.3823\n",
      "Epoch 3/100\n",
      "2188/2188 [==============================] - 73s 33ms/step - loss: 280.6532 - mae: 9.0228 - val_loss: 260.1825 - val_mae: 8.3852\n",
      "Epoch 4/100\n",
      "2188/2188 [==============================] - 74s 34ms/step - loss: 259.5383 - mae: 8.4847 - val_loss: 245.6789 - val_mae: 8.2110\n",
      "Epoch 5/100\n",
      "2188/2188 [==============================] - 77s 35ms/step - loss: 244.6443 - mae: 8.1083 - val_loss: 235.6538 - val_mae: 7.9944\n",
      "Epoch 6/100\n",
      "2188/2188 [==============================] - 68s 31ms/step - loss: 233.7692 - mae: 7.8227 - val_loss: 224.6614 - val_mae: 7.4497\n",
      "Epoch 7/100\n",
      "2188/2188 [==============================] - 74s 34ms/step - loss: 226.4243 - mae: 7.6412 - val_loss: 224.9382 - val_mae: 7.5125\n",
      "Epoch 8/100\n",
      "2188/2188 [==============================] - 83s 38ms/step - loss: 222.0326 - mae: 7.5119 - val_loss: 215.6004 - val_mae: 7.1343\n",
      "Epoch 9/100\n",
      "2188/2188 [==============================] - 81s 37ms/step - loss: 217.7801 - mae: 7.4044 - val_loss: 215.4453 - val_mae: 7.2947\n",
      "Epoch 10/100\n",
      "2188/2188 [==============================] - 79s 36ms/step - loss: 215.2468 - mae: 7.3401 - val_loss: 212.3643 - val_mae: 7.4777\n",
      "Epoch 11/100\n",
      "2188/2188 [==============================] - 82s 37ms/step - loss: 212.3360 - mae: 7.2773 - val_loss: 251.8096 - val_mae: 9.2308\n",
      "Epoch 12/100\n",
      "2188/2188 [==============================] - 71s 32ms/step - loss: 210.8718 - mae: 7.2066 - val_loss: 210.0073 - val_mae: 6.9087\n",
      "Epoch 13/100\n",
      "2188/2188 [==============================] - 84s 39ms/step - loss: 209.2547 - mae: 7.1804 - val_loss: 211.3100 - val_mae: 7.1337\n",
      "Epoch 14/100\n",
      "2188/2188 [==============================] - 76s 35ms/step - loss: 207.6618 - mae: 7.1477 - val_loss: 212.7539 - val_mae: 6.7346\n",
      "Epoch 15/100\n",
      "2188/2188 [==============================] - 76s 35ms/step - loss: 205.1459 - mae: 7.0897 - val_loss: 206.2543 - val_mae: 7.2084\n",
      "Epoch 16/100\n",
      "2188/2188 [==============================] - 91s 41ms/step - loss: 203.9076 - mae: 7.0494 - val_loss: 204.5403 - val_mae: 6.9656\n",
      "Epoch 17/100\n",
      "2188/2188 [==============================] - 82s 37ms/step - loss: 201.8692 - mae: 7.0214 - val_loss: 208.2016 - val_mae: 7.2139\n",
      "Epoch 18/100\n",
      "2188/2188 [==============================] - 84s 39ms/step - loss: 201.5925 - mae: 6.9974 - val_loss: 204.7432 - val_mae: 7.1537\n",
      "Epoch 19/100\n",
      "2188/2188 [==============================] - 83s 38ms/step - loss: 199.0027 - mae: 6.9536 - val_loss: 201.8844 - val_mae: 6.7453\n",
      "Epoch 20/100\n",
      "2188/2188 [==============================] - 88s 40ms/step - loss: 198.4318 - mae: 6.9143 - val_loss: 200.4255 - val_mae: 7.1150\n",
      "Epoch 21/100\n",
      "2188/2188 [==============================] - 80s 36ms/step - loss: 197.4449 - mae: 6.9217 - val_loss: 199.1282 - val_mae: 6.7895\n",
      "Epoch 22/100\n",
      "2188/2188 [==============================] - 83s 38ms/step - loss: 195.8222 - mae: 6.8265 - val_loss: 199.6071 - val_mae: 6.9085\n",
      "Epoch 23/100\n",
      "2188/2188 [==============================] - 81s 37ms/step - loss: 194.7447 - mae: 6.8454 - val_loss: 196.6695 - val_mae: 6.9463\n",
      "Epoch 24/100\n",
      "2188/2188 [==============================] - 77s 35ms/step - loss: 193.5209 - mae: 6.8202 - val_loss: 202.6869 - val_mae: 7.1015\n",
      "Epoch 25/100\n",
      "2188/2188 [==============================] - 80s 36ms/step - loss: 192.7919 - mae: 6.7804 - val_loss: 197.0070 - val_mae: 6.7182\n",
      "Epoch 26/100\n",
      "2188/2188 [==============================] - 78s 36ms/step - loss: 192.2348 - mae: 6.7768 - val_loss: 197.1481 - val_mae: 6.7660\n",
      "Epoch 27/100\n",
      "2188/2188 [==============================] - 74s 34ms/step - loss: 191.2536 - mae: 6.7508 - val_loss: 197.0503 - val_mae: 6.6475\n",
      "Epoch 28/100\n",
      "2188/2188 [==============================] - 77s 35ms/step - loss: 190.8189 - mae: 6.7523 - val_loss: 209.0293 - val_mae: 7.7686\n",
      "Epoch 29/100\n",
      "2188/2188 [==============================] - 81s 37ms/step - loss: 189.9103 - mae: 6.7238 - val_loss: 199.3177 - val_mae: 7.1349\n",
      "Epoch 30/100\n",
      "2188/2188 [==============================] - 78s 36ms/step - loss: 189.4759 - mae: 6.7070 - val_loss: 221.3949 - val_mae: 6.7821\n",
      "Epoch 31/100\n",
      "2188/2188 [==============================] - 76s 35ms/step - loss: 189.7110 - mae: 6.7010 - val_loss: 194.1002 - val_mae: 6.5238\n",
      "Epoch 32/100\n",
      "2188/2188 [==============================] - 74s 34ms/step - loss: 188.3772 - mae: 6.6705 - val_loss: 195.5772 - val_mae: 6.9227\n",
      "Epoch 33/100\n",
      "2188/2188 [==============================] - 75s 34ms/step - loss: 186.6176 - mae: 6.6389 - val_loss: 197.4939 - val_mae: 7.1031\n",
      "Epoch 34/100\n",
      "  75/2188 [>.............................] - ETA: 1:05 - loss: 180.4510 - mae: 6.7212"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23060/398144585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_scaled_train, y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           epochs=100)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1092\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/modelo_energetico/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_scaled_train, y_train,\n",
    "          validation_data=(X_scaled_test, y_test), \n",
    "          batch_size=32,\n",
    "          epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
